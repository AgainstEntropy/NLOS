{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cache/wangyihao/miniconda3/envs/NLOS/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/mnt/cache/wangyihao/miniconda3/envs/NLOS/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import time\n",
    "#\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "from scipy.io import savemat, loadmat\n",
    "# import torch\n",
    "# from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "# import torchvision.utils as tvutils\n",
    "from torchsummary import summary\n",
    "\n",
    "# import cv2\n",
    "# import PIL\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from my_utils.vis import *\n",
    "from my_utils import models\n",
    "# from my_utils.utils import check_accuracy\n",
    "from my_utils.data.dataset import raw_png_processor, raw_video_processor, MyDataset\n",
    "from my_utils.data.loader import load_frames\n",
    "from my_utils.data.preprocess import sub_mean, reduce\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # set default size of plots\n",
    "\n",
    "# life save magic code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.12.0+cu113\n",
      "There are 1 GPUs in total.\n",
      "The first GPU is: _CudaDeviceProperties(name='NVIDIA A100-SXM4-80GB', major=8, minor=0, total_memory=81251MB, multi_processor_count=108)\n",
      "CUDA version: 11.3\n",
      "Using cuda:0 now!\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    GPU_nums = torch.cuda.device_count()\n",
    "    GPU = torch.cuda.get_device_properties(0)\n",
    "    print(f\"There are {GPU_nums} GPUs in total.\\nThe first GPU is: {GPU}\")\n",
    "    if '3060' in GPU.name:\n",
    "        print(f\"CUDA version: {torch.cuda_version}\")\n",
    "    else:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "device = torch.device(f\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using {device} now!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tv_r21d_model = tv.models.video.r2plus1d_18()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "my_r21d_model = models.NLOS_r21d(depths=(2,1), dims=(16, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "my_conv_model = models.NLOS_Conv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "png_abs_dir = '/mnt/lustre/wangyihao/nlos_raw_pngs/train/Being hit_p0_r0_grey_tiling_07-16-15-49'\n",
    "frames = load_frames(png_abs_dir, frame_range=(0, 64))\n",
    "print(frames.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "frames_sub_mean = sub_mean(frames).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frames_sub_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 64, 128, 128])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_frames = torch.from_numpy(mat).permute(3, 0, 1, 2).unsqueeze(0)\n",
    "input_frames.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m my_r21d_model((input_frames, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[0;31mTypeError\u001B[0m: new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "my_r21d_model((input_frames, torch.Tensor([0,], dtype=torch.float)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 8, 64, 64, 64]           1,176\n",
      "       BatchNorm3d-2        [-1, 8, 64, 64, 64]              16\n",
      "              ReLU-3        [-1, 8, 64, 64, 64]               0\n",
      "            Conv3d-4       [-1, 16, 64, 64, 64]             384\n",
      "       BatchNorm3d-5       [-1, 16, 64, 64, 64]              32\n",
      "              ReLU-6       [-1, 16, 64, 64, 64]               0\n",
      "            Conv3d-7       [-1, 36, 64, 64, 64]           5,184\n",
      "       BatchNorm3d-8       [-1, 36, 64, 64, 64]              72\n",
      "              ReLU-9       [-1, 36, 64, 64, 64]               0\n",
      "           Conv3d-10       [-1, 16, 64, 64, 64]           1,728\n",
      "      BatchNorm3d-11       [-1, 16, 64, 64, 64]              32\n",
      "             ReLU-12       [-1, 16, 64, 64, 64]               0\n",
      "           Conv3d-13       [-1, 36, 64, 64, 64]           5,184\n",
      "      BatchNorm3d-14       [-1, 36, 64, 64, 64]              72\n",
      "             ReLU-15       [-1, 36, 64, 64, 64]               0\n",
      "           Conv3d-16       [-1, 16, 64, 64, 64]           1,728\n",
      "      BatchNorm3d-17       [-1, 16, 64, 64, 64]              32\n",
      "             ReLU-18       [-1, 16, 64, 64, 64]               0\n",
      "    R2Plus1DBlock-19       [-1, 16, 64, 64, 64]               0\n",
      "           Conv3d-20       [-1, 36, 64, 64, 64]           5,184\n",
      "      BatchNorm3d-21       [-1, 36, 64, 64, 64]              72\n",
      "             ReLU-22       [-1, 36, 64, 64, 64]               0\n",
      "           Conv3d-23       [-1, 16, 64, 64, 64]           1,728\n",
      "      BatchNorm3d-24       [-1, 16, 64, 64, 64]              32\n",
      "             ReLU-25       [-1, 16, 64, 64, 64]               0\n",
      "           Conv3d-26       [-1, 36, 64, 64, 64]           5,184\n",
      "      BatchNorm3d-27       [-1, 36, 64, 64, 64]              72\n",
      "             ReLU-28       [-1, 36, 64, 64, 64]               0\n",
      "           Conv3d-29       [-1, 16, 64, 64, 64]           1,728\n",
      "      BatchNorm3d-30       [-1, 16, 64, 64, 64]              32\n",
      "             ReLU-31       [-1, 16, 64, 64, 64]               0\n",
      "    R2Plus1DBlock-32       [-1, 16, 64, 64, 64]               0\n",
      "           Conv3d-33       [-1, 57, 64, 32, 32]           8,208\n",
      "      BatchNorm3d-34       [-1, 57, 64, 32, 32]             114\n",
      "             ReLU-35       [-1, 57, 64, 32, 32]               0\n",
      "           Conv3d-36       [-1, 32, 32, 32, 32]           5,472\n",
      "      BatchNorm3d-37       [-1, 32, 32, 32, 32]              64\n",
      "             ReLU-38       [-1, 32, 32, 32, 32]               0\n",
      "           Conv3d-39       [-1, 57, 32, 32, 32]          16,416\n",
      "      BatchNorm3d-40       [-1, 57, 32, 32, 32]             114\n",
      "             ReLU-41       [-1, 57, 32, 32, 32]               0\n",
      "           Conv3d-42       [-1, 32, 32, 32, 32]           5,472\n",
      "      BatchNorm3d-43       [-1, 32, 32, 32, 32]              64\n",
      "           Conv3d-44       [-1, 32, 32, 32, 32]             512\n",
      "      BatchNorm3d-45       [-1, 32, 32, 32, 32]              64\n",
      "             ReLU-46       [-1, 32, 32, 32, 32]               0\n",
      "    R2Plus1DBlock-47       [-1, 32, 32, 32, 32]               0\n",
      "AdaptiveAvgPool3d-48          [-1, 32, 1, 1, 1]               0\n",
      "           Linear-49                   [-1, 20]             660\n",
      "================================================================\n",
      "Total params: 66,832\n",
      "Trainable params: 66,832\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 12.00\n",
      "Forward/backward pass size (MB): 1656.25\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 1668.51\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(my_r21d_model.to(device), input_size=(3, 64, 128, 128), batch_size=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mat_file = loadmat(file_name='/mnt/lustre/wangyihao/nlos_raw_pngs/train/Lying down_p2_r0_white_tiling_07-15-03-16/video_128_N0.mat')\n",
    "mat = mat_file['video']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 128, 3)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_pool = torch.nn.AdaptiveAvgPool2d(output_size=(1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 32])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool(torch.randn(size=(8, 32, 128, 64))).flatten(start_dim=1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 128, 128])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(mat).permute(3, 0, 1, 2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
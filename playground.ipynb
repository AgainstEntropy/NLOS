{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cache/wangyihao/miniconda3/envs/NLOS/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/mnt/cache/wangyihao/miniconda3/envs/NLOS/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:25: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import time\n",
    "#\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "from scipy.io import savemat, loadmat\n",
    "# import torch\n",
    "# from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms._transforms_video import ToTensorVideo\n",
    "# import torchvision.utils as tvutils\n",
    "from torchsummary import summary\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "\n",
    "# import cv2\n",
    "# import PIL\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from my_utils.vis import *\n",
    "from my_utils import models\n",
    "# from my_utils.utils import check_accuracy\n",
    "from my_utils.data.dataset import raw_png_processor, raw_video_processor, MyDataset\n",
    "from my_utils.data.loader import load_frames\n",
    "from my_utils.data.preprocess import sub_mean, reduce\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # set default size of plots\n",
    "\n",
    "# life save magic code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.12.0+cu113\n",
      "There are 1 GPUs in total.\n",
      "The first GPU is: _CudaDeviceProperties(name='NVIDIA A100-SXM4-80GB', major=8, minor=0, total_memory=81251MB, multi_processor_count=108)\n",
      "CUDA version: 11.3\n",
      "Using cuda:0 now!\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    GPU_nums = torch.cuda.device_count()\n",
    "    GPU = torch.cuda.get_device_properties(0)\n",
    "    print(f\"There are {GPU_nums} GPUs in total.\\nThe first GPU is: {GPU}\")\n",
    "    if '3060' in GPU.name:\n",
    "        print(f\"CUDA version: {torch.cuda_version}\")\n",
    "    else:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "device = torch.device(f\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using {device} now!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tv_r21d_model = tv.models.video.r2plus1d_18()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "my_r21d_model = models.NLOS_r21d(layers=[1,2], channels=[16, 32])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "my_conv_model = models.NLOS_Conv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "png_abs_dir = '/mnt/lustre/wangyihao/nlos_raw_pngs/train/Being hit_p0_r0_grey_tiling_07-16-15-49'\n",
    "frames = load_frames(png_abs_dir, frame_range=(0, 64))\n",
    "print(frames.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "frames_sub_mean = sub_mean(frames).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[[ 0.40625 ,  0.390625,  0.3125  ],\n         [-0.015625,  0.390625,  0.484375],\n         [ 0.0625  , -0.609375, -0.46875 ],\n         ...,\n         [ 0.15625 ,  0.59375 ,  0.296875],\n         [-0.6875  , -0.953125, -1.03125 ],\n         [ 1.078125,  1.34375 ,  1.296875]],\n\n        [[-0.046875,  0.8125  ,  0.46875 ],\n         [ 0.265625,  0.40625 ,  0.171875],\n         [-0.375   , -0.296875, -0.5     ],\n         ...,\n         [-0.21875 ,  0.203125,  0.421875],\n         [ 0.296875, -0.140625, -0.171875],\n         [-0.65625 , -0.21875 , -0.609375]],\n\n        [[ 0.3125  ,  0.421875,  0.234375],\n         [ 0.5     ,  0.515625,  0.484375],\n         [ 0.      ,  0.171875, -0.21875 ],\n         ...,\n         [-0.265625, -0.25    ,  0.109375],\n         [ 0.      ,  0.59375 ,  0.265625],\n         [-0.109375,  0.09375 ,  0.03125 ]],\n\n        ...,\n\n        [[-0.1875  , -0.03125 ,  0.125   ],\n         [ 0.25    ,  0.375   ,  0.59375 ],\n         [ 0.109375,  0.625   ,  0.65625 ],\n         ...,\n         [-1.03125 , -1.015625, -1.046875],\n         [ 0.28125 , -0.015625,  0.3125  ],\n         [-1.03125 , -1.1875  , -0.875   ]],\n\n        [[ 0.171875,  0.421875,  0.125   ],\n         [-0.015625,  0.125   ,  0.21875 ],\n         [ 0.765625,  0.890625, -0.03125 ],\n         ...,\n         [-1.328125, -0.71875 , -1.171875],\n         [-0.96875 , -0.90625 , -1.515625],\n         [ 0.171875,  0.390625, -0.359375]],\n\n        [[-0.296875, -0.15625 , -0.15625 ],\n         [ 0.328125,  0.5     ,  0.4375  ],\n         [-0.546875, -0.1875  , -0.671875],\n         ...,\n         [-0.890625, -0.5     , -0.359375],\n         [-0.6875  , -0.375   , -0.484375],\n         [-1.375   , -0.984375, -0.796875]]],\n\n\n       [[[ 0.40625 ,  0.390625,  0.3125  ],\n         [-0.015625,  0.390625,  0.484375],\n         [-0.9375  , -0.609375, -0.46875 ],\n         ...,\n         [ 0.15625 , -0.40625 ,  0.296875],\n         [-0.6875  , -0.953125, -1.03125 ],\n         [ 1.078125,  1.34375 ,  1.296875]],\n\n        [[-0.046875,  0.8125  ,  0.46875 ],\n         [ 0.265625,  0.40625 ,  0.171875],\n         [ 0.625   ,  0.703125,  0.5     ],\n         ...,\n         [ 0.78125 ,  0.203125,  0.421875],\n         [-0.703125, -0.140625, -0.171875],\n         [-0.65625 , -0.21875 , -0.609375]],\n\n        [[ 0.3125  , -0.578125,  0.234375],\n         [ 1.5     ,  1.515625,  1.484375],\n         [ 2.      ,  2.171875,  1.78125 ],\n         ...,\n         [-0.265625, -0.25    ,  0.109375],\n         [ 0.      ,  0.59375 ,  0.265625],\n         [-0.109375,  0.09375 ,  0.03125 ]],\n\n        ...,\n\n        [[-0.1875  , -0.03125 ,  0.125   ],\n         [ 0.25    ,  0.375   ,  0.59375 ],\n         [ 1.109375,  0.625   ,  0.65625 ],\n         ...,\n         [-1.03125 , -1.015625, -1.046875],\n         [ 0.28125 , -0.015625,  0.3125  ],\n         [-2.03125 , -1.1875  , -1.875   ]],\n\n        [[ 0.171875,  0.421875,  0.125   ],\n         [ 0.984375,  0.125   ,  0.21875 ],\n         [-0.234375, -0.109375, -0.03125 ],\n         ...,\n         [-0.328125, -0.71875 , -0.171875],\n         [-0.96875 , -0.90625 , -1.515625],\n         [ 0.171875,  0.390625, -0.359375]],\n\n        [[-0.296875, -0.15625 , -0.15625 ],\n         [ 0.328125,  0.5     ,  0.4375  ],\n         [-0.546875, -0.1875  , -0.671875],\n         ...,\n         [-0.890625, -0.5     , -1.359375],\n         [-0.6875  , -0.375   , -0.484375],\n         [ 0.625   , -0.984375, -0.796875]]],\n\n\n       [[[ 0.40625 ,  0.390625,  0.3125  ],\n         [-0.015625,  0.390625,  0.484375],\n         [ 0.0625  ,  0.390625, -0.46875 ],\n         ...,\n         [ 0.15625 , -0.40625 ,  0.296875],\n         [-0.6875  , -0.953125, -1.03125 ],\n         [ 1.078125,  1.34375 ,  1.296875]],\n\n        [[-0.046875,  0.8125  ,  0.46875 ],\n         [-0.734375, -0.59375 ,  0.171875],\n         [-0.375   , -0.296875, -0.5     ],\n         ...,\n         [ 0.78125 ,  0.203125,  0.421875],\n         [ 0.296875, -0.140625, -0.171875],\n         [-0.65625 , -0.21875 , -0.609375]],\n\n        [[-0.6875  , -0.578125,  0.234375],\n         [ 0.5     ,  0.515625,  0.484375],\n         [ 0.      ,  0.171875,  0.78125 ],\n         ...,\n         [-0.265625, -0.25    ,  0.109375],\n         [ 0.      ,  0.59375 ,  0.265625],\n         [-0.109375,  0.09375 ,  0.03125 ]],\n\n        ...,\n\n        [[-0.1875  , -0.03125 ,  0.125   ],\n         [ 0.25    ,  0.375   ,  0.59375 ],\n         [ 1.109375,  0.625   ,  0.65625 ],\n         ...,\n         [-1.03125 , -1.015625, -1.046875],\n         [ 0.28125 , -0.015625,  0.3125  ],\n         [-2.03125 , -1.1875  , -1.875   ]],\n\n        [[ 0.171875,  0.421875,  0.125   ],\n         [-0.015625,  0.125   ,  0.21875 ],\n         [-0.234375, -0.109375, -0.03125 ],\n         ...,\n         [-0.328125, -0.71875 , -0.171875],\n         [-0.96875 , -0.90625 , -1.515625],\n         [ 0.171875, -0.609375, -0.359375]],\n\n        [[-0.296875, -0.15625 , -0.15625 ],\n         [ 0.328125,  0.5     ,  0.4375  ],\n         [-1.546875, -1.1875  , -0.671875],\n         ...,\n         [-0.890625, -0.5     , -0.359375],\n         [-0.6875  , -0.375   , -0.484375],\n         [-1.375   , -0.984375, -0.796875]]],\n\n\n       ...,\n\n\n       [[[ 0.40625 ,  0.390625,  0.3125  ],\n         [-0.015625,  0.390625,  0.484375],\n         [-0.9375  , -0.609375, -0.46875 ],\n         ...,\n         [ 0.15625 , -0.40625 ,  0.296875],\n         [ 0.3125  ,  1.046875,  0.96875 ],\n         [-1.921875, -1.65625 , -1.703125]],\n\n        [[-0.046875, -0.1875  ,  0.46875 ],\n         [-0.734375, -0.59375 , -0.828125],\n         [-0.375   , -0.296875, -0.5     ],\n         ...,\n         [-0.21875 ,  0.203125,  0.421875],\n         [-0.703125, -1.140625, -1.171875],\n         [ 0.34375 , -0.21875 ,  0.390625]],\n\n        [[-0.6875  , -0.578125, -0.765625],\n         [ 0.5     ,  0.515625,  0.484375],\n         [ 0.      ,  0.171875, -0.21875 ],\n         ...,\n         [-0.265625, -0.25    ,  0.109375],\n         [ 0.      ,  0.59375 ,  0.265625],\n         [-0.109375,  0.09375 ,  0.03125 ]],\n\n        ...,\n\n        [[-0.1875  , -0.03125 ,  0.125   ],\n         [ 0.25    ,  0.375   , -0.40625 ],\n         [ 0.109375,  0.625   , -0.34375 ],\n         ...,\n         [-0.03125 , -0.015625, -0.046875],\n         [ 0.28125 , -0.015625,  0.3125  ],\n         [-1.03125 , -1.1875  , -0.875   ]],\n\n        [[ 0.171875,  0.421875,  0.125   ],\n         [-0.015625,  0.125   ,  0.21875 ],\n         [-0.234375, -0.109375, -0.03125 ],\n         ...,\n         [-0.328125, -0.71875 , -0.171875],\n         [-0.96875 , -0.90625 , -0.515625],\n         [ 0.171875,  0.390625,  0.640625]],\n\n        [[ 0.703125, -0.15625 , -0.15625 ],\n         [ 0.328125,  0.5     ,  0.4375  ],\n         [ 0.453125, -0.1875  ,  0.328125],\n         ...,\n         [-0.890625, -0.5     , -0.359375],\n         [ 0.3125  , -0.375   , -0.484375],\n         [-0.375   ,  0.015625, -0.796875]]],\n\n\n       [[[ 0.40625 ,  0.390625,  0.3125  ],\n         [-1.015625, -0.609375, -0.515625],\n         [-0.9375  , -0.609375, -0.46875 ],\n         ...,\n         [ 1.15625 ,  0.59375 ,  0.296875],\n         [-0.6875  ,  0.046875, -0.03125 ],\n         [-2.921875, -2.65625 , -2.703125]],\n\n        [[-1.046875, -1.1875  , -0.53125 ],\n         [-0.734375, -0.59375 , -0.828125],\n         [ 0.625   , -0.296875,  0.5     ],\n         ...,\n         [-0.21875 ,  0.203125, -0.578125],\n         [-0.703125, -0.140625, -0.171875],\n         [ 0.34375 , -0.21875 ,  0.390625]],\n\n        [[ 0.3125  ,  0.421875,  0.234375],\n         [-1.5     , -1.484375, -1.515625],\n         [ 0.      ,  0.171875, -0.21875 ],\n         ...,\n         [-1.265625, -1.25    , -0.890625],\n         [ 0.      , -0.40625 , -0.734375],\n         [-1.109375, -0.90625 , -0.96875 ]],\n\n        ...,\n\n        [[-0.1875  , -0.03125 ,  0.125   ],\n         [-0.75    , -0.625   , -0.40625 ],\n         [ 1.109375,  0.625   ,  0.65625 ],\n         ...,\n         [-0.03125 , -0.015625, -0.046875],\n         [ 0.28125 , -0.015625,  0.3125  ],\n         [ 0.96875 ,  0.8125  ,  0.125   ]],\n\n        [[-0.828125, -0.578125, -0.875   ],\n         [-1.015625, -0.875   , -0.78125 ],\n         [-0.234375, -0.109375, -0.03125 ],\n         ...,\n         [-0.328125,  0.28125 , -0.171875],\n         [ 0.03125 ,  0.09375 ,  0.484375],\n         [ 0.171875,  0.390625, -0.359375]],\n\n        [[ 0.703125,  0.84375 ,  0.84375 ],\n         [-0.671875, -0.5     , -0.5625  ],\n         [ 0.453125,  0.8125  ,  1.328125],\n         ...,\n         [ 1.109375,  0.5     ,  0.640625],\n         [-0.6875  , -0.375   , -0.484375],\n         [ 0.625   ,  0.015625,  0.203125]]],\n\n\n       [[[-0.59375 , -0.609375, -0.6875  ],\n         [-0.015625,  0.390625,  0.484375],\n         [ 0.0625  ,  0.390625,  0.53125 ],\n         ...,\n         [ 0.15625 , -0.40625 ,  0.296875],\n         [-0.6875  ,  0.046875, -0.03125 ],\n         [-2.921875, -2.65625 , -2.703125]],\n\n        [[-0.046875, -0.1875  , -0.53125 ],\n         [-1.734375, -1.59375 , -0.828125],\n         [-0.375   , -0.296875, -0.5     ],\n         ...,\n         [-2.21875 , -1.796875, -2.578125],\n         [-0.703125, -0.140625, -0.171875],\n         [ 0.34375 , -0.21875 ,  0.390625]],\n\n        [[-0.6875  , -0.578125, -0.765625],\n         [-0.5     , -0.484375, -0.515625],\n         [-2.      , -2.828125, -2.21875 ],\n         ...,\n         [-0.265625, -0.25    , -0.890625],\n         [ 0.      , -0.40625 , -0.734375],\n         [-1.109375, -0.90625 , -0.96875 ]],\n\n        ...,\n\n        [[-1.1875  , -1.03125 , -0.875   ],\n         [-0.75    , -0.625   , -1.40625 ],\n         [-0.890625, -1.375   , -1.34375 ],\n         ...,\n         [ 0.96875 ,  0.984375,  0.953125],\n         [-0.71875 , -0.015625, -0.6875  ],\n         [ 1.96875 ,  0.8125  ,  1.125   ]],\n\n        [[-0.828125, -1.578125, -0.875   ],\n         [-1.015625, -0.875   , -1.78125 ],\n         [-0.234375, -0.109375, -1.03125 ],\n         ...,\n         [ 0.671875,  0.28125 ,  0.828125],\n         [ 2.03125 ,  2.09375 ,  1.484375],\n         [-2.828125, -2.609375, -3.359375]],\n\n        [[-0.296875, -0.15625 , -0.15625 ],\n         [ 0.328125,  0.5     ,  0.4375  ],\n         [-1.546875, -1.1875  , -1.671875],\n         ...,\n         [ 1.109375,  0.5     ,  0.640625],\n         [-1.6875  , -1.375   , -0.484375],\n         [ 0.625   ,  1.015625,  0.203125]]]], dtype=float32)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_sub_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 64, 128, 128])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_frames = torch.from_numpy(mat).permute(3, 0, 1, 2).unsqueeze(0)\n",
    "input_frames.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m my_r21d_model((input_frames, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[0;31mTypeError\u001B[0m: new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "my_r21d_model((input_frames, torch.Tensor([0,], dtype=torch.float)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 16, 128, 64]           2,352\n",
      "       BatchNorm2d-2          [-1, 16, 128, 64]              32\n",
      "         LeakyReLU-3          [-1, 16, 128, 64]               0\n",
      "            Conv2d-4          [-1, 16, 128, 64]          12,544\n",
      "       BatchNorm2d-5          [-1, 16, 128, 64]              32\n",
      "         LeakyReLU-6          [-1, 16, 128, 64]               0\n",
      "            Conv2d-7          [-1, 16, 128, 64]          12,544\n",
      "       BatchNorm2d-8          [-1, 16, 128, 64]              32\n",
      "         LeakyReLU-9          [-1, 16, 128, 64]               0\n",
      "           Conv2d-10          [-1, 16, 128, 64]          12,544\n",
      "      BatchNorm2d-11          [-1, 16, 128, 64]              32\n",
      "        LeakyReLU-12          [-1, 16, 128, 64]               0\n",
      "           Conv2d-13          [-1, 32, 128, 64]          25,088\n",
      "      BatchNorm2d-14          [-1, 32, 128, 64]              64\n",
      "        LeakyReLU-15          [-1, 32, 128, 64]               0\n",
      "AdaptiveAvgPool2d-16             [-1, 32, 1, 1]               0\n",
      "              GAP-17                       [-1]               0\n",
      "           Linear-18                       [-1]             660\n",
      "================================================================\n",
      "Total params: 65,924\n",
      "Trainable params: 65,924\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 18.00\n",
      "Params size (MB): 0.25\n",
      "Estimated Total Size (MB): 18.35\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(my_conv_model.to('cuda:0'), input_size=(1, 3, 128, 64), batch_size=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mat_file = loadmat(file_name='/mnt/lustre/wangyihao/nlos_raw_pngs/train/Lying down_p2_r0_white_tiling_07-15-03-16/video_128_N0.mat')\n",
    "mat = mat_file['video']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 128, 3)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_pool = torch.nn.AdaptiveAvgPool2d(output_size=(1, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([8, 32])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_pool(torch.randn(size=(8, 32, 128, 64))).flatten(start_dim=1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 128, 128])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(mat).permute(3, 0, 1, 2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
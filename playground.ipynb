{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# import os\n",
    "# import time\n",
    "#\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy\n",
    "from scipy.io import savemat, loadmat\n",
    "# import torch\n",
    "# from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision as tv\n",
    "from torchvision import transforms\n",
    "# import torchvision.utils as tvutils\n",
    "from torchsummary import summary\n",
    "\n",
    "# import cv2\n",
    "# import PIL\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from my_utils.vis import *\n",
    "from my_utils import models\n",
    "# from my_utils.utils import check_accuracy\n",
    "from my_utils.data.dataset import raw_png_processor, raw_video_processor, MyDataset\n",
    "from my_utils.data.loader import load_frames\n",
    "from my_utils.data.preprocess import sub_mean, reduce\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)  # set default size of plots\n",
    "\n",
    "# life save magic code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.12.0+cu113\n",
      "There are 1 GPUs in total.\n",
      "The first GPU is: _CudaDeviceProperties(name='NVIDIA A100-SXM4-80GB', major=8, minor=0, total_memory=81251MB, multi_processor_count=108)\n",
      "CUDA version: 11.3\n",
      "Using cuda:0 now!\n"
     ]
    }
   ],
   "source": [
    "print(f\"torch version: {torch.__version__}\")\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    GPU_nums = torch.cuda.device_count()\n",
    "    GPU = torch.cuda.get_device_properties(0)\n",
    "    print(f\"There are {GPU_nums} GPUs in total.\\nThe first GPU is: {GPU}\")\n",
    "    if '3060' in GPU.name:\n",
    "        print(f\"CUDA version: {torch.cuda_version}\")\n",
    "    else:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "device = torch.device(f\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(f\"Using {device} now!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tv_r21d_model = tv.models.video.r2plus1d_18()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "my_r21d_model = models.NLOS_r21d(depths=(2,1), dims=(16, 32))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "my_conv_model = models.NLOS_Conv(groups=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256, 256, 3])\n"
     ]
    }
   ],
   "source": [
    "png_abs_dir = '/mnt/lustre/wangyihao/nlos_raw_pngs/train/Being hit_p0_r0_grey_tiling_07-16-15-49'\n",
    "frames = load_frames(png_abs_dir, frame_range=(0, 64))\n",
    "print(frames.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "frames_sub_mean = sub_mean(frames).numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frames_sub_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 64, 128, 128])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_frames = torch.from_numpy(mat).permute(3, 0, 1, 2).unsqueeze(0)\n",
    "input_frames.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [35]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m my_r21d_model((input_frames, \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[0;31mTypeError\u001B[0m: new() received an invalid combination of arguments - got (list, dtype=torch.dtype), but expected one of:\n * (*, torch.device device)\n      didn't match because some of the keywords were incorrect: dtype\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n * (object data, *, torch.device device)\n"
     ]
    }
   ],
   "source": [
    "my_r21d_model((input_frames, torch.Tensor([0,], dtype=torch.float)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 32, 64, 128]           4,704\n",
      "       BatchNorm2d-2          [-1, 32, 64, 128]              64\n",
      "         LeakyReLU-3          [-1, 32, 64, 128]               0\n",
      "            Conv2d-4          [-1, 32, 64, 128]          25,088\n",
      "       BatchNorm2d-5          [-1, 32, 64, 128]              64\n",
      "         LeakyReLU-6          [-1, 32, 64, 128]               0\n",
      "            Conv2d-7          [-1, 32, 64, 128]          25,088\n",
      "       BatchNorm2d-8          [-1, 32, 64, 128]              64\n",
      "         LeakyReLU-9          [-1, 32, 64, 128]               0\n",
      "           Conv2d-10          [-1, 32, 64, 128]          25,088\n",
      "      BatchNorm2d-11          [-1, 32, 64, 128]              64\n",
      "        LeakyReLU-12          [-1, 32, 64, 128]               0\n",
      "           Conv2d-13          [-1, 64, 64, 128]          50,176\n",
      "      BatchNorm2d-14          [-1, 64, 64, 128]             128\n",
      "        LeakyReLU-15          [-1, 64, 64, 128]               0\n",
      "AdaptiveAvgPool2d-16             [-1, 64, 1, 1]               0\n",
      "           Linear-17                   [-1, 20]           1,300\n",
      "================================================================\n",
      "Total params: 131,828\n",
      "Trainable params: 131,828\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 36.00\n",
      "Params size (MB): 0.50\n",
      "Estimated Total Size (MB): 36.69\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(my_conv_model.to(device), input_size=(6, 128, 128), batch_size=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "mat_file = loadmat(file_name='/mnt/lustre/wangyihao/nlos_raw_pngs/train/Lying down_p2_r0_white_tiling_07-15-03-16/video_128_N0.mat')\n",
    "mat = mat_file['video']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 128, 3)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 64, 128, 128])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(mat).permute(3, 0, 1, 2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 64, 3)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = np.random.rand(128, 64, 3)\n",
    "W = np.random.rand(128, 64, 3)\n",
    "W.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "concatenate() missing required argument 'seq' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrays\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m<__array_function__ internals>:5\u001B[0m, in \u001B[0;36mconcatenate\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: concatenate() missing required argument 'seq' (pos 1)"
     ]
    }
   ],
   "source": [
    "np.concatenate(seq=(H, W), axis=2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(128, 64, 6)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dstack((H, W)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}